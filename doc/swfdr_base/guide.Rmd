---
title: 'User Guide: Science-Wise False Discovery Rate'
author: "Nathan (Nat) Goodman"
date: "June 1, 2017"
output:
  html_document:
    css: ../css/html_document.css
    highlight: kate
  pdf_document:
    keep_tex: yes
    toc: yes
    toc_depth: 3
linkcolor: cyan
citecolor: green
urlcolor: blue
---
```{r echo=FALSE,include=FALSE,cache=FALSE}
library(knitr)
library(kableExtra); # dunno why this is needed, but it is...
## setup variables for documentation paths
knitr::read_chunk('../tool/doclinks.R');
knitr::read_chunk('../tool/argtable.R');
out=knitr::opts_knit$get("rmarkdown.pandoc.to");
```
```{r echo=FALSE,include=FALSE,cache=FALSE}
<<doclinks>>
<<argtable>>
```

*This user guide explains how to install and run the scripts in my [SWFDR GitHub repository](https://github.com/natgoodman/SWFDR) and briefly describes the rest of the distribution. The base script is `swfdr_base.R`, a simple implementation that uses base R capabilities only. Other scripts extend the base implementation by providing solutions to some [exercises for the reader](`r exercises`).*

---
## `swfdr_base.R` ##

This script reimplements the core idea in 
[David Colquhoun's fascinating paper](http://rsos.royalsocietypublishing.org/content/1/3/140216), "An investigation of the false discovery rate and the misinterpretation of p-values" and further discussed in [Felix Schönbrodt's blog post](http://www.nicebread.de/whats-the-probability-that-a-significant-p-value-indicates-a-true-effect/), "What’s the probability that a significant p-value indicates a true effect?" and related [ShinyApp](http://shinyapps.org/apps/PPV/). The term *science-wise false discovery rate* is from [Jager and Leek's paper](http://doi.org/10.1093/biostatistics/kxt007), "An estimate of the science-wise false discovery rate and application to the top medical literature". [John Ioannidis’s landmark paper](http://dx.plos.org/10.1371/journal.pmed.0020124), “Why most published research findings are false”, is the origin of it all.

The *false discovery rate* (*FDR*) is the probability that a significant p-value indicates a false positive, or equivalently, the proportion of significant p-values that correspond to results without a real effect.  The complement, *positive predictive value (PPV=1-FDR)* is the probability that a significant p-value indicates a true positive, or equivalently, the proportion of significant p-values that correspond to results with real effects.

The script produces graphs of FDR for a range of parameter values. The user can easily change parameters and rerun the program.

### Installation and Usage ###

The simplest way to get the software is to download the entire repository. The software is in the `script` subdirectory. At present, the only available script is `swfdr_base.R`. This program uses base R capabilities only and will run "out of the box" on any (reasonably modern) R installation.
 
The recommended way to run `swfdr_base.R` is to source the program into your R session and run the statement `run();` The code below illustrates the default process and some variants.

``` {r eval=FALSE}
# this code block assumes your working directory is the root of the repository

source("script/swfdr_base.R");
# run default process
run();

# run default process and save results in directories data/guide01 and figure/guide01
run(save=T,datadir='data/guide01',figdir='figure/guide01');

# reduce runtime by reducing number of simulation runs and simulated cases
run(m=1e3,d=c(0.25,0.5,1),prop.true=c(0.3,0.5,0.8));

# specify power directly and let program adjust effect size
run(m=1e3,pwr=c(0.1,0.3,0.8),prop.true=c(0.3,0.5,0.8));

# skip computation by loading saved results and replotting graphs
loadit();
doplot();

# load saved results and do something completely different
# for example, plot distribution of effect size error for small effects with significant p-values 
loadit();
with(subset(sim,subset=(d==0.25&d.true&pval<=0.05)),hist(diff-d));
```
The default process performs $2.5 \times 10^5$ simulations (taking about 3 minutes on my small Linux server) and produces four graphs similar to the ones below (in directory `figure/swfdr_base`). The other examples are much faster. The plots for the three `run` examples and the final histogram example are in directories `figure/guide01`, etc. The plots for the `loadit(); doplot();` example are identical to the default process.

```{r out.width="50%",echo=FALSE,fig.show='asis'}
knitr::include_graphics('../figure/swfdr_base/plot_byprop.png');
knitr::include_graphics('../figure/swfdr_base/plot_byd.png');
knitr::include_graphics('../figure/swfdr_base/plot_vsprop.png');
knitr::include_graphics('../figure/swfdr_base/plot_vsd.png');
```

The notation is

-  solid lines show theoretical results; dashed lines are empirical results from the simulation
-  *fdr*. false discovery rate
-  *pval*. p-value cutoff for significance
-  *prop.true*. proportion of simulated cases that have a real effect
-  *d*. standardized effect size, aka *Cohen's d*

The user can change simulation parameters and control program operation by providing new values to `run()` as illustrated in the example code block above. The available parameters are

| parameter |     meaning     | default |
| ------------- | -------------------------------------------- | ------------- |
| prop.true | fraction of cases where there is a real effect | `seq(.1,.9,by=.2)` |
| m | number of iterations | `1e4` |
| n | sample size | `16` |
| d | standardized effect size (aka *Cohen's d*) | `c(.25,.50,.75,1,2)` |
| pwr | power. if set, program adjusts *d* to achieve power | `NA` |
| sig.level | significance level for power calculations when *pwr* is set | `0.05` |
| pval.plot | p-values for which we plot results | `c(.001,.01,.03,.05,.1)` |
|  |  | |
| scriptname | used to set output directories and in error messages |`'swfdr_base'` |
| datadir | data directory relative to distribution root | `'data/swfdr_base'` |
| figdir | figure directory relative to distribution root | `'figure/swfdr_base'` |
| save | save parameters, results, and plots; <br/>sets *save.rdata* and *save.plot*, not *save.txt* | `FALSE` |
| save.rdata | save parameters and results in RData format | `FALSE` (set by *save*)|
| save.txt | save results in txt format. **CAUTION: big and slow** | `FALSE` (not set by *save*) |
| save.plot | save plots | `FALSE` (set by *save*)|
| clean | remove contents of data and figure directories; <br/>sets *clean.data* and *clean.fig* | `FALSE` |
| clean.data | remove contents of data directory | `FALSE` (set by *clean*) |
| clean.fig | remove contents of figure directory | `FALSE` (set by *clean*) |

### Statistical Details ###

-  The program assumes normally distributed data with equal variance. 
-  The p-values are from a two-sided, unpaired, equal variance t-test (R's `t.test` with default settings for `alternative`, `paired`, and `var.equal`).
-  The default sample size ($n=16$) gives about 80% power for $d=1$ and $sig.level=0.05$. Power for the full range of $d$ is

| *d*   | 0.25 | 0.50 | 0.75 | 1.00 | 2.00   |
| ---   | ---- | ---- | ---- | ---- | :----: |
| power | 0.10 | 0.28 | 0.54 | 0.78 | 0.9998 |


## Directory Structure ##

The root directory contains the usual GitHub files: LICENSE, README.md, .gitignore. There's also a NEWS.md file that lists major differences between releases. The subdirectories are

- `css/` - style sheets used by the document generation process
- `data/` - data files
- `doc/` - documentation 
- `figure/` - plots 
- `script/` - scripts
- `tool/` - helper scripts for the document generation process

## Other Scripts ##
TBD

## Functions ##

```{r parent-guide, child = sapply(c('run','init','doit','plot-functions'),function(x) paste(sep='','guide/',x,'.swfdr_base.Rmd'))}
```

## Documentation ##
The documentation comprises 

- this User Guide
- [README](`r README`)
- [NEWS](`r NEWS`) lists major differences between releases 
- R-style [function-level documentation](TBD) 
- [Science: Science-Wise False Discovery Rate](`r science`) explains the scientific concepts underlying the software
- [Software: Science-Wise False Discovery Rate](`r software`) discusses the software design and design choices
- [Exercises: Science-Wise False Discovery Rate](`r exercises`) provides exercises for the reader to improve the program

Document files have several formats.

1. R markdown (`Rmd`) is the source format. I generate the ooutput formats programmatically using, e.g., 
``` {r eval=FALSE}
rmarkdown::render(doc/README.Rmd,'github_document')
rmarkdown::render(doc/guide.Rmd,(c('html_document','pdf_document'))
```
2. markdown (`md`) is the output format GitHub prefers for documents displayed on its site. Due to limitations in GitHub's `md` support, I only use this format for simple documents, viz,. README and NEWS.
3. `html`. These are self-contained HTML files that should display correctly on your local computer or website. Because they are self-contained, they tend to be huge and inscrutable. Note that GitHub shows HTML files as raw text, which is not very illuminating, but has an [HTML preview feature](http://htmlpreview.github.io) that renders the files as expected.
4. `pdf`. GitHub renders the files as expected **but disables links**.

## See Also ##

Felix Schönbrodt's [blog post](http://www.nicebread.de/whats-the-probability-that-a-significant-p-value-indicates-a-true-effect/) and [ShinyApp](http://shinyapps.org/apps/PPV/) got me going down this path and offer an insightful, different perspective. Blog posts by [Daniel Lakens](http://daniellakens.blogspot.de/2015/09/how-can-p-005-lead-to-wrong-conclusions.html) and [Will Gervais](http://willgervais.com/blog/2014/9/24/power-consequences>) are also interesting.

Papers by [David Colquhoun](http://rsos.royalsocietypublishing.org/content/1/3/140216), [Leah Jager and Jeffrey Leek](http://doi.org/10.1093/biostatistics/kxt007), and [John Ioannidis](http://dx.plos.org/10.1371/journal.pmed.0020124) cover it all with full statistical rigor and much more detail.

## Author ##

Nathan (Nat) Goodman, (natg at shore.net)

## Bugs and Caveats ##

Please report any bugs, other problems, and feature requests using the [GitHub Issue Tracker](https://github.com/natgoodman/FDR/issues). I will be notified, and you'll be apprised of progress.

### Known Bugs and Caveats ###

-  The simulation results are noisy for $m$ < 5x10<sup>3</sup> and dubious for $m$ < 10<sup>3</sup>; the program does not run at all for $m$ < 2.
-  The software is pretty basic. See [Exercises: Science-Wise False Discovery Rate](`r exercises`) for a list of known limitations.


## Copyright & License ##

Copyright (c) 2017 Nathan Goodman

The software is **open source and free**, released under the [MIT License](https://opensource.org/licenses/MIT).
